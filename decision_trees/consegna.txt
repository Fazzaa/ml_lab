Esercizio n. 1 (Meo) in Laboratorio sugli alberi di decisione con sci kit learn:
applicate un sovracampionamento (artificial inflation) ad una classe nel training set con un determinato fattore: 10 (si pesi di più una delle classi tra virginica o versicolor che sono più difficili da discriminare). Si apprenda l'albero di decisione in queste condizioni. Attenzione che in questo caso la suddivisione tra training set e test set non deve rilasciare nel test set nessuna delle copie che abbiamo aggiunto, altrimenti si favorirebbe troppo il classificatore dando copie presenti nel training set anche nel test set. Quindi se volete usare la crossvalidation, dovete farla voi, da programma Python "a mano" (e non usare quella fornita da scikit learn, che non fa questo controllo).
b) modifcare i pesi della stessa classe (si metta a 10 il peso per l'errata predizione ad esempio di Virginica in Versicolor o viceversa) e si apprenda l'albero in queste condizioni. Dovreste ottenere risultati simili a quelli del punto 1.
Si apprendano gli alberi cercando di evitare l'overfitting (migliorando l'errore sul test set) facendo 'tuning' degli iper-parametri: il minimo numero dei campioni per foglia, la massima profondità dell'albero, i parametri di minomo decremento dell'impurezza, massimo numero dei nodi foglia, ecc.
si costruisca la matrice di confusione dell'albero creato sul test set e la si visualizzi. 
si costruiscano le curve ROC (o curve nello spazio di coverage) e le si mostri per ciascun modello ad albero creato su un problema binario (con 1 sola classe positiva): per ciascun modello dovete costruire tre curve, una per ciascuna classe, considerata a turno la classe positiva.