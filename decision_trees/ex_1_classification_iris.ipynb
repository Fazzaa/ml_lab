{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Esercizio 1: Classification Iris"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dataset: https://archive.ics.uci.edu/ml/datasets/iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree \n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import cross_val_score \n",
    "import graphviz \n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "from itertools import repeat\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### load the dataset and split it in train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Initialize the model and fit with the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the weights are the same for all the classes\n",
    "clf = tree.DecisionTreeClassifier(criterion=\"entropy\",random_state=300,min_samples_leaf=5,class_weight={0:1,1:1,2:1}) \n",
    "clf = clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Predict the classes of the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_y_test = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Printing information about the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted classes:\n",
      "[0 1 1 0 2 1 2 0 0 2 1 0 2 1 1 0 1 1 0 0 1 1 2 0 2 1 0 0 1 2 1 2 1 2 2 0 1\n",
      " 0 1 2 2 0 1 2 1]\n",
      "\n",
      "real classes:\n",
      "[0 1 1 0 2 1 2 0 0 2 1 0 2 1 1 0 1 1 0 0 1 1 1 0 2 1 0 0 1 2 1 2 1 2 2 0 1\n",
      " 0 1 2 2 0 2 2 1]\n",
      "\n",
      "correctly classified examples: 43\n",
      "number of errors: 2\n"
     ]
    }
   ],
   "source": [
    "print(f\"predicted classes:\\n{predicted_y_test}\\n\")\n",
    "print(f\"real classes:\\n{y_test}\")\n",
    "print(f\"\\ncorrectly classified examples: {sum(predicted_y_test == y_test)}\")\n",
    "print(f\"number of errors: {sum(predicted_y_test != y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(y_test)):\n",
    "    print(f\"class {iris.target_names[y_test[i]]} predicted as {iris.target_names[predicted_y_test[i]]}\")\n",
    "    for j in range(len(iris.feature_names)):\n",
    "        print(f\"{iris.feature_names[j]}: {X_test[i][j]}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Accuracy and F1 of the model \n",
    "- F1 = 2 * (precision * recall) / (precision + recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9555555555555556\n",
      "f1 score: 0.9558404558404558\n"
     ]
    }
   ],
   "source": [
    "print(f\"accuracy: {accuracy_score(y_test, predicted_y_test)}\")\n",
    "f1 = f1_score(y_test, predicted_y_test, average='macro') # macro means that the score is calculated for each class and then averaged\n",
    "print(f\"f1 score: {f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross validation scores: [0.96666667 1.         0.86666667 0.86666667 1.        ]\n",
      "cross validation f1 scores: [0.96658312 1.         0.86111111 0.86666667 1.        ]\n"
     ]
    }
   ],
   "source": [
    "#cross validation\n",
    "accuracy_scores = cross_val_score(clf, iris.data, iris.target, cv=5) # default score is the accuracy, 5-fold cross validation\n",
    "print(f\"cross validation scores: {accuracy_scores}\")\n",
    "f1_scores = cross_val_score(clf, iris.data, iris.target, cv=5, scoring='f1_macro') \n",
    "print(f\"cross validation f1 scores: {f1_scores}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Visualize the Tree with Graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 7.0.3 (20221126.0506)\n -->\n<!-- Title: Tree Pages: 1 -->\n<svg width=\"660pt\" height=\"552pt\"\n viewBox=\"0.00 0.00 660.00 552.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 548)\">\n<title>Tree</title>\n<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-548 656,-548 656,4 -4,4\"/>\n<!-- 0 -->\n<g id=\"node1\" class=\"node\">\n<title>0</title>\n<path fill=\"#ffffff\" stroke=\"black\" d=\"M366,-544C366,-544 225,-544 225,-544 219,-544 213,-538 213,-532 213,-532 213,-473 213,-473 213,-467 219,-461 225,-461 225,-461 366,-461 366,-461 372,-461 378,-467 378,-473 378,-473 378,-532 378,-532 378,-538 372,-544 366,-544\"/>\n<text text-anchor=\"start\" x=\"221\" y=\"-528.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">petal length (cm) ≤ 2.45</text>\n<text text-anchor=\"start\" x=\"245.5\" y=\"-513.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 1.585</text>\n<text text-anchor=\"start\" x=\"248\" y=\"-498.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 150</text>\n<text text-anchor=\"start\" x=\"235\" y=\"-483.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [50, 50, 50]</text>\n<text text-anchor=\"start\" x=\"249.5\" y=\"-468.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = setosa</text>\n</g>\n<!-- 1 -->\n<g id=\"node2\" class=\"node\">\n<title>1</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M265,-417.5C265,-417.5 168,-417.5 168,-417.5 162,-417.5 156,-411.5 156,-405.5 156,-405.5 156,-361.5 156,-361.5 156,-355.5 162,-349.5 168,-349.5 168,-349.5 265,-349.5 265,-349.5 271,-349.5 277,-355.5 277,-361.5 277,-361.5 277,-405.5 277,-405.5 277,-411.5 271,-417.5 265,-417.5\"/>\n<text text-anchor=\"start\" x=\"174.5\" y=\"-402.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\n<text text-anchor=\"start\" x=\"173\" y=\"-387.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 50</text>\n<text text-anchor=\"start\" x=\"164\" y=\"-372.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [50, 0, 0]</text>\n<text text-anchor=\"start\" x=\"170.5\" y=\"-357.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = setosa</text>\n</g>\n<!-- 0&#45;&gt;1 -->\n<g id=\"edge1\" class=\"edge\">\n<title>0&#45;&gt;1</title>\n<path fill=\"none\" stroke=\"black\" d=\"M267.87,-460.58C260.57,-449.77 252.68,-438.09 245.33,-427.19\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"248.37,-425.44 239.87,-419.12 242.57,-429.36 248.37,-425.44\"/>\n<text text-anchor=\"middle\" x=\"234.27\" y=\"-438.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">True</text>\n</g>\n<!-- 2 -->\n<g id=\"node3\" class=\"node\">\n<title>2</title>\n<path fill=\"#ffffff\" stroke=\"black\" d=\"M442,-425C442,-425 307,-425 307,-425 301,-425 295,-419 295,-413 295,-413 295,-354 295,-354 295,-348 301,-342 307,-342 307,-342 442,-342 442,-342 448,-342 454,-348 454,-354 454,-354 454,-413 454,-413 454,-419 448,-425 442,-425\"/>\n<text text-anchor=\"start\" x=\"303\" y=\"-409.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">petal width (cm) ≤ 1.75</text>\n<text text-anchor=\"start\" x=\"332.5\" y=\"-394.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 1.0</text>\n<text text-anchor=\"start\" x=\"327\" y=\"-379.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 100</text>\n<text text-anchor=\"start\" x=\"318\" y=\"-364.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 50, 50]</text>\n<text text-anchor=\"start\" x=\"319\" y=\"-349.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = versicolor</text>\n</g>\n<!-- 0&#45;&gt;2 -->\n<g id=\"edge2\" class=\"edge\">\n<title>0&#45;&gt;2</title>\n<path fill=\"none\" stroke=\"black\" d=\"M323.13,-460.58C328.82,-452.16 334.86,-443.2 340.74,-434.5\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"343.48,-436.7 346.17,-426.45 337.67,-432.78 343.48,-436.7\"/>\n<text text-anchor=\"middle\" x=\"351.78\" y=\"-446.04\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">False</text>\n</g>\n<!-- 3 -->\n<g id=\"node4\" class=\"node\">\n<title>3</title>\n<path fill=\"#4de88e\" stroke=\"black\" d=\"M354,-306C354,-306 213,-306 213,-306 207,-306 201,-300 201,-294 201,-294 201,-235 201,-235 201,-229 207,-223 213,-223 213,-223 354,-223 354,-223 360,-223 366,-229 366,-235 366,-235 366,-294 366,-294 366,-300 360,-306 354,-306\"/>\n<text text-anchor=\"start\" x=\"209\" y=\"-290.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">petal length (cm) ≤ 4.95</text>\n<text text-anchor=\"start\" x=\"233.5\" y=\"-275.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.445</text>\n<text text-anchor=\"start\" x=\"240\" y=\"-260.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 54</text>\n<text text-anchor=\"start\" x=\"231\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 49, 5]</text>\n<text text-anchor=\"start\" x=\"228\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = versicolor</text>\n</g>\n<!-- 2&#45;&gt;3 -->\n<g id=\"edge3\" class=\"edge\">\n<title>2&#45;&gt;3</title>\n<path fill=\"none\" stroke=\"black\" d=\"M342.67,-341.58C336.05,-333.07 329.01,-324.01 322.18,-315.23\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"324.99,-313.14 316.08,-307.39 319.46,-317.44 324.99,-313.14\"/>\n</g>\n<!-- 8 -->\n<g id=\"node9\" class=\"node\">\n<title>8</title>\n<path fill=\"#843de6\" stroke=\"black\" d=\"M537,-306C537,-306 396,-306 396,-306 390,-306 384,-300 384,-294 384,-294 384,-235 384,-235 384,-229 390,-223 396,-223 396,-223 537,-223 537,-223 543,-223 549,-229 549,-235 549,-235 549,-294 549,-294 549,-300 543,-306 537,-306\"/>\n<text text-anchor=\"start\" x=\"392\" y=\"-290.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">petal length (cm) ≤ 4.95</text>\n<text text-anchor=\"start\" x=\"416.5\" y=\"-275.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.151</text>\n<text text-anchor=\"start\" x=\"423\" y=\"-260.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 46</text>\n<text text-anchor=\"start\" x=\"414\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 1, 45]</text>\n<text text-anchor=\"start\" x=\"416.5\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = virginica</text>\n</g>\n<!-- 2&#45;&gt;8 -->\n<g id=\"edge8\" class=\"edge\">\n<title>2&#45;&gt;8</title>\n<path fill=\"none\" stroke=\"black\" d=\"M406.68,-341.58C413.37,-333.07 420.49,-324.01 427.4,-315.23\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"430.13,-317.41 433.56,-307.39 424.63,-313.09 430.13,-317.41\"/>\n</g>\n<!-- 4 -->\n<g id=\"node5\" class=\"node\">\n<title>4</title>\n<path fill=\"#3de684\" stroke=\"black\" d=\"M208,-187C208,-187 63,-187 63,-187 57,-187 51,-181 51,-175 51,-175 51,-116 51,-116 51,-110 57,-104 63,-104 63,-104 208,-104 208,-104 214,-104 220,-110 220,-116 220,-116 220,-175 220,-175 220,-181 214,-187 208,-187\"/>\n<text text-anchor=\"start\" x=\"59\" y=\"-171.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">sepal length (cm) ≤ 5.15</text>\n<text text-anchor=\"start\" x=\"85.5\" y=\"-156.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.146</text>\n<text text-anchor=\"start\" x=\"92\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 48</text>\n<text text-anchor=\"start\" x=\"83\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 47, 1]</text>\n<text text-anchor=\"start\" x=\"80\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = versicolor</text>\n</g>\n<!-- 3&#45;&gt;4 -->\n<g id=\"edge4\" class=\"edge\">\n<title>3&#45;&gt;4</title>\n<path fill=\"none\" stroke=\"black\" d=\"M231.74,-222.58C220.25,-213.49 207.96,-203.79 196.15,-194.45\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"198.44,-191.79 188.42,-188.34 194.1,-197.28 198.44,-191.79\"/>\n</g>\n<!-- 7 -->\n<g id=\"node8\" class=\"node\">\n<title>7</title>\n<path fill=\"#c09cf2\" stroke=\"black\" d=\"M342.5,-179.5C342.5,-179.5 250.5,-179.5 250.5,-179.5 244.5,-179.5 238.5,-173.5 238.5,-167.5 238.5,-167.5 238.5,-123.5 238.5,-123.5 238.5,-117.5 244.5,-111.5 250.5,-111.5 250.5,-111.5 342.5,-111.5 342.5,-111.5 348.5,-111.5 354.5,-117.5 354.5,-123.5 354.5,-123.5 354.5,-167.5 354.5,-167.5 354.5,-173.5 348.5,-179.5 342.5,-179.5\"/>\n<text text-anchor=\"start\" x=\"246.5\" y=\"-164.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.918</text>\n<text text-anchor=\"start\" x=\"257\" y=\"-149.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 6</text>\n<text text-anchor=\"start\" x=\"248\" y=\"-134.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 2, 4]</text>\n<text text-anchor=\"start\" x=\"246.5\" y=\"-119.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = virginica</text>\n</g>\n<!-- 3&#45;&gt;7 -->\n<g id=\"edge7\" class=\"edge\">\n<title>3&#45;&gt;7</title>\n<path fill=\"none\" stroke=\"black\" d=\"M288.05,-222.58C289.17,-212.43 290.39,-201.5 291.54,-191.18\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"295,-191.69 292.63,-181.37 288.04,-190.92 295,-191.69\"/>\n</g>\n<!-- 5 -->\n<g id=\"node6\" class=\"node\">\n<title>5</title>\n<path fill=\"#6aeca0\" stroke=\"black\" d=\"M115,-68C115,-68 12,-68 12,-68 6,-68 0,-62 0,-56 0,-56 0,-12 0,-12 0,-6 6,0 12,0 12,0 115,0 115,0 121,0 127,-6 127,-12 127,-12 127,-56 127,-56 127,-62 121,-68 115,-68\"/>\n<text text-anchor=\"start\" x=\"13.5\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.722</text>\n<text text-anchor=\"start\" x=\"24\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 5</text>\n<text text-anchor=\"start\" x=\"15\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 4, 1]</text>\n<text text-anchor=\"start\" x=\"8\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = versicolor</text>\n</g>\n<!-- 4&#45;&gt;5 -->\n<g id=\"edge5\" class=\"edge\">\n<title>4&#45;&gt;5</title>\n<path fill=\"none\" stroke=\"black\" d=\"M108.69,-103.73C103.11,-95.24 97.22,-86.28 91.6,-77.73\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"94.65,-76 86.23,-69.56 88.8,-79.84 94.65,-76\"/>\n</g>\n<!-- 6 -->\n<g id=\"node7\" class=\"node\">\n<title>6</title>\n<path fill=\"#39e581\" stroke=\"black\" d=\"M260,-68C260,-68 157,-68 157,-68 151,-68 145,-62 145,-56 145,-56 145,-12 145,-12 145,-6 151,0 157,0 157,0 260,0 260,0 266,0 272,-6 272,-12 272,-12 272,-56 272,-56 272,-62 266,-68 260,-68\"/>\n<text text-anchor=\"start\" x=\"166.5\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\n<text text-anchor=\"start\" x=\"165\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 43</text>\n<text text-anchor=\"start\" x=\"156\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 43, 0]</text>\n<text text-anchor=\"start\" x=\"153\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = versicolor</text>\n</g>\n<!-- 4&#45;&gt;6 -->\n<g id=\"edge6\" class=\"edge\">\n<title>4&#45;&gt;6</title>\n<path fill=\"none\" stroke=\"black\" d=\"M162.68,-103.73C168.34,-95.24 174.31,-86.28 180.01,-77.73\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"182.83,-79.82 185.46,-69.56 177,-75.94 182.83,-79.82\"/>\n</g>\n<!-- 9 -->\n<g id=\"node10\" class=\"node\">\n<title>9</title>\n<path fill=\"#9a61ea\" stroke=\"black\" d=\"M500.5,-179.5C500.5,-179.5 408.5,-179.5 408.5,-179.5 402.5,-179.5 396.5,-173.5 396.5,-167.5 396.5,-167.5 396.5,-123.5 396.5,-123.5 396.5,-117.5 402.5,-111.5 408.5,-111.5 408.5,-111.5 500.5,-111.5 500.5,-111.5 506.5,-111.5 512.5,-117.5 512.5,-123.5 512.5,-123.5 512.5,-167.5 512.5,-167.5 512.5,-173.5 506.5,-179.5 500.5,-179.5\"/>\n<text text-anchor=\"start\" x=\"408.5\" y=\"-164.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.65</text>\n<text text-anchor=\"start\" x=\"415\" y=\"-149.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 6</text>\n<text text-anchor=\"start\" x=\"406\" y=\"-134.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 1, 5]</text>\n<text text-anchor=\"start\" x=\"404.5\" y=\"-119.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = virginica</text>\n</g>\n<!-- 8&#45;&gt;9 -->\n<g id=\"edge9\" class=\"edge\">\n<title>8&#45;&gt;9</title>\n<path fill=\"none\" stroke=\"black\" d=\"M462.3,-222.58C461.26,-212.43 460.14,-201.5 459.08,-191.18\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"462.58,-190.96 458.08,-181.37 455.61,-191.67 462.58,-190.96\"/>\n</g>\n<!-- 10 -->\n<g id=\"node11\" class=\"node\">\n<title>10</title>\n<path fill=\"#8139e5\" stroke=\"black\" d=\"M640,-179.5C640,-179.5 543,-179.5 543,-179.5 537,-179.5 531,-173.5 531,-167.5 531,-167.5 531,-123.5 531,-123.5 531,-117.5 537,-111.5 543,-111.5 543,-111.5 640,-111.5 640,-111.5 646,-111.5 652,-117.5 652,-123.5 652,-123.5 652,-167.5 652,-167.5 652,-173.5 646,-179.5 640,-179.5\"/>\n<text text-anchor=\"start\" x=\"549.5\" y=\"-164.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\n<text text-anchor=\"start\" x=\"548\" y=\"-149.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 40</text>\n<text text-anchor=\"start\" x=\"539\" y=\"-134.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 0, 40]</text>\n<text text-anchor=\"start\" x=\"541.5\" y=\"-119.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = virginica</text>\n</g>\n<!-- 8&#45;&gt;10 -->\n<g id=\"edge10\" class=\"edge\">\n<title>8&#45;&gt;10</title>\n<path fill=\"none\" stroke=\"black\" d=\"M510.22,-222.58C522.35,-211.23 535.51,-198.9 547.65,-187.55\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"549.84,-190.28 554.75,-180.9 545.06,-185.17 549.84,-190.28\"/>\n</g>\n</g>\n</svg>\n",
      "text/plain": [
       "<graphviz.sources.Source at 0x1ccdd1b2340>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize another classifier to visualize the graph on the total examples\n",
    "clf_graph = tree.DecisionTreeClassifier(criterion=\"entropy\",random_state=300,min_samples_leaf=5,class_weight={0:1,1:1,2:1})\n",
    "clf_graph = clf_graph.fit(iris.data, iris.target)\n",
    "\n",
    "dot_data = tree.export_graphviz(clf_graph, out_file=None, \n",
    "                                feature_names=iris.feature_names,\n",
    "                                class_names=iris.target_names,\n",
    "                                filled=True, rounded=True,\n",
    "                                special_characters=True)\n",
    "graph = graphviz.Source(dot_data)\n",
    "graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The maximum entropy is log2(3) = 1.585\n",
    "- The minimum entropy is 0\n",
    "- The class is chosen by the majority of the samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.a Oversampling (Artificial Inflation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applicate un sovracampionamento (artificial inflation) ad una classe nel training set con un determinato fattore: 10 (si pesi di più una delle classi tra virginica o versicolor che sono più difficili da discriminare). Si apprenda l'albero di decisione in queste condizioni."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oversampling(X_train, y_train, oversampling_factor):\n",
    "\tX_train_augmented = []\n",
    "\ty_train_augmented = []\n",
    "\tfor (x,y) in zip(X_train, y_train):\n",
    "\t\tif y == 2:\n",
    "\t\t\tX_train_augmented.extend(repeat(x, oversampling_factor))\n",
    "\t\t\ty_train_augmented.extend(repeat(y, oversampling_factor))\n",
    "\t\telse:\n",
    "\t\t\tX_train_augmented.append(x)\n",
    "\t\t\ty_train_augmented.append(y)\n",
    "\treturn X_train_augmented, y_train_augmented\n",
    "\n",
    "def compute_fp_tp_fn_tn(real_value, predicted_value, positive_class):\n",
    "\t# returns tuple (fp, tp, fn, tn)\n",
    "\tfp, tp, fn, tn = 0, 0, 0, 0\n",
    "\tfor i in range(len(real_value)):\n",
    "\t\tif real_value[i] == positive_class and predicted_value[i] == positive_class:\n",
    "\t\t\ttp += 1\n",
    "\t\telif real_value[i] != positive_class and predicted_value[i] == positive_class:\n",
    "\t\t\tfp += 1\n",
    "\t\telif real_value[i] == positive_class and predicted_value[i] != positive_class:\n",
    "\t\t\tfn += 1\n",
    "\t\telif real_value[i] != positive_class and predicted_value[i] != positive_class:\n",
    "\t\t\ttn += 1\n",
    "\treturn fp, tp, fn, tn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "OVERSAMPLING_FACTOR = 10\n",
    "\n",
    "clf_oversampling = tree.DecisionTreeClassifier(criterion=\"entropy\",random_state=300,min_samples_leaf=5,class_weight={0:1,1:1,2:1})\n",
    "\n",
    "iris = load_iris()\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.3, random_state=1)\n",
    "\n",
    "X_train_oversample, y_train_oversample = oversampling(X_train, y_train, OVERSAMPLING_FACTOR)\n",
    "\n",
    "clf_oversampling = clf_oversampling.fit(X_train_oversample, y_train_oversample)\n",
    "\n",
    "predicted_y_test = clf_oversampling.predict(X_test)\n",
    "\n",
    "fp, tp, fn, tn = 0, 0, 0, 0\n",
    "for i in range(0,3):\n",
    "\tfp, tp, fn, tn = compute_fp_tp_fn_tn(y_test, predicted_y_test, i)\n",
    "\tprint(f\"accuracy_homemade for class {i}: {(tp+tn) / (tp+tn+fp+fn)}\")\n",
    "\tprint(f\"precision for class {i}: {tp / (tp+fp)}\")\n",
    "\tprint(f\"recall for class {i} : {tp / (tp+fn)}\")\n",
    "\t\n",
    "\n",
    "print(f\"accuracy: {accuracy_score(y_test, predicted_y_test)}\")\n",
    "\n",
    "f1 = f1_score(y_test, predicted_y_test, average='macro') # macro means that the score is calculated for each class and then averaged\n",
    "print(f\"f1 score: {f1}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.b Modify weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9777777777777777\n",
      "f1 score: 0.9781305114638448\n"
     ]
    }
   ],
   "source": [
    "clf_weights = tree.DecisionTreeClassifier(criterion=\"entropy\",random_state=300,min_samples_leaf=5,class_weight={0:1,1:1,2:10})\n",
    "iris = load_iris()\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.3, random_state=1)\n",
    "\n",
    "clf_weights = clf_weights.fit(X_train, y_train)\n",
    "\n",
    "predicted_y_test = clf_weights.predict(X_test)\n",
    "\n",
    "print(f\"accuracy: {accuracy_score(y_test, predicted_y_test)}\")\n",
    "f1 = f1_score(y_test, predicted_y_test, average='macro') # macro means that the score is calculated for each class and then averaged\n",
    "print(f\"f1 score: {f1}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7efb2d7ff2df1439e00fdb3d4f2694a3ec3140441601882caf0cf9a3f70ee73c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
